# anova min
if anova_type == "min":
        # calcolo risultati utilizzando diversi valori anova avg
        anova_val_tested = []
        anova_val_tested_str = []
        n_feature_per_aval = []
        accuracies = []
        n_neurons = 0
        # in base a cosa sono stati calcolati i range per selezionare i valori anova?
        for a_val in range_lst:
            less_than_anova_vals = []
            greater_than_anova_vals = []
            # si sceglie l'index delle feature che andranno a comporre l'input del modello
            for idx, val in enumerate(varianza_min_classi):
                if val > a_val / divider:
                    greater_than_anova_vals.append(idx)
                else:
                    less_than_anova_vals.append(idx)

            # chiedere se per ogni osservazione si selezionano le feature minori ai valori anova tramite index
            X_lower_anova = X_train[:, less_than_anova_vals]
            X_greater_anova = X_train[:, greater_than_anova_vals]

            n_neurons = m_neurons = neurons

            som = MiniSom(
                n_neurons,
                m_neurons,
                X_lower_anova.shape[1],
                sigma=5,
                learning_rate=0.1,
                neighborhood_function="gaussian",
                activation_distance="manhattan",
            )

           
            som.random_weights_init(X_lower_anova)
            som.train_random(X_lower_anova, train_iter, verbose=False)  # random training

            if save_data == 'y':
                if not os.path.exists('./' + mod_path +"/" + dataset_type + '/anova_' + sys.argv[2] + '/' + str(a_val / divider) + '/'):
                    os.mkdir('./' + mod_path +"/" + dataset_type + '/anova_' + sys.argv[2] + '/' + str(a_val / divider) + '/')

            if not os.path.exists(
                "./"
                + plots_path
                +"/" + dataset_type
                + "/anova_min/som_"
                + sys.argv[1]
                + "_"
                + str(n_neurons)
            ):
                os.mkdir(
                    "./"
                    + plots_path
                    +"/" + dataset_type
                    + "/anova_min/som_"
                    + sys.argv[1]
                    + "_"
                    + str(n_neurons)
                )
            if save_data == "y":
                plot_som(
                    som,
                    X_lower_anova,
                    y_train,
                    "./"
                    + plots_path
                    +"/" + dataset_type
                    + "/anova_min/som_"
                    + sys.argv[1]
                    + "_"
                    + str(n_neurons)
                    + "/som_iter-"
                    + str(train_iter)
                    + "_plot_",
                    a_val / divider,
                    X_lower_anova.shape[1],
                    save_data,
                    subjects_number
                )
            w = som.get_weights()
        
            #La notazione -1 in una delle dimensioni indica a NumPy di inferire
            #automaticamente la dimensione in modo tale da mantenere il numero 
            #totale di elementi invariato. In questo caso, viene inferito in modo 
            #tale da mantenere il numero di elementi nella terza dimensione 
            #(l'ultimo elemento di w.shape) invariato.
            w = w.reshape((-1, w.shape[2]))

            #if not old_som_dim == current_som_dim:
               
            if save_data == "y":
                if not os.path.exists(
                    "./" + np_arr_path +"/" + dataset_type + "/anova_min/" + str(a_val / divider) + "/"
                ):
                    os.mkdir(
                        "./"
                        + np_arr_path
                        +"/" + dataset_type
                        + "/anova_min/"
                        + str(a_val / divider)
                        + "/"
                    )
                np.savetxt(
                    "./"
                    + np_arr_path
                    +"/" + dataset_type
                    + "/anova_min/"
                    + str(a_val / divider)
                    + "/weights_lst_min_iter-"
                    + str(train_iter)
                    + "_"
                    + ("subjects-" + str(subjects_number) + "_" if sys.argv[4] == "split" else "")
                    + sys.argv[1]
                    + "_"
                    + str(neurons)
                    + ".txt",
                    w,
                    delimiter=" ",
                )

                if not os.path.exists(
                    "./" + mod_path +"/" + dataset_type + "/anova_min/" + str(a_val / divider) + "/"
                ):
                    os.mkdir(
                        "./" + mod_path +"/" + dataset_type + "/anova_min/" + str(a_val / divider) + "/"
                    )
                #old_som_dim = current_som_dim
            class_report = classification_report(
                new_y_test,
                classify(
                    som,
                    X_test[:, less_than_anova_vals],
                    X_lower_anova,
                    y_train,
                    n_neurons,
                    "min",
                    a_val / divider,
                    train_iter,
                ),
                zero_division=0.0,
                output_dict=True,
            )

            save_model(som, mod_path, sys.argv[2], str(a_val / divider), str(n_neurons), dataset_type)
           
            anova_val_tested.append(a_val / divider)
            anova_val_tested_str.append(str(a_val / divider))
            n_feature_per_aval.append(X_lower_anova.shape[1])
            accuracies.append(class_report["accuracy"])
            # insert in accuracy dictionary the accuracy for anova val
            accs_tot_min[a_val / divider].append(class_report["accuracy"])
            actual_exec += 1
            percentage = round((actual_exec / total_execs) * 100, 2)
            print("\rProgress: ", percentage, "%", end="")

                
            acc_anova_min_lst.append(accuracies)
            n_feat_anova_min_lst.append(n_feature_per_aval)



INFO flwr 2023-10-26 11:24:51,193 | app.py:175 | Starting Flower simulation, config: ServerConfig(num_rounds=8, round_timeout=None)
2023-10-26 11:24:59,080 INFO worker.py:1621 -- Started a local Ray instance.
INFO flwr 2023-10-26 11:25:03,983 | app.py:210 | Flower VCE: Ray initialized with resources: {'CPU': 8.0, 'node:127.0.0.1': 1.0, 'memory': 1355548263.0, 'object_store_memory': 677774131.0, 'node:__internal_head__': 1.0}
INFO flwr 2023-10-26 11:25:03,984 | app.py:218 | No `client_resources` specified. Using minimal resources for clients.
INFO flwr 2023-10-26 11:25:03,985 | app.py:224 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 0.0}
INFO flwr 2023-10-26 11:25:04,045 | app.py:270 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2023-10-26 11:25:04,047 | server.py:89 | Initializing global parameters
INFO flwr 2023-10-26 11:25:04,048 | server.py:276 | Requesting initial parameters from one random client
INFO flwr 2023-10-26 11:25:51,939 | server.py:280 | Received initial parameters from one random client
INFO flwr 2023-10-26 11:25:51,940 | server.py:91 | Evaluating initial parameters
INFO flwr 2023-10-26 11:25:51,941 | server.py:104 | FL starting
DEBUG flwr 2023-10-26 11:25:51,942 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 10)
DEBUG flwr 2023-10-26 11:25:54,045 | server.py:236 | fit_round 1 received 10 results and 0 failures
WARNING flwr 2023-10-26 11:25:54,054 | fedavg.py:242 | No fit_metrics_aggregation_fn provided
DEBUG flwr 2023-10-26 11:25:54,055 | server.py:173 | evaluate_round 1: strategy sampled 10 clients (out of 10)
(DefaultActor pid=16336) DEBUG flwr 2023-10-26 11:25:54,183 | main.py:187 | Evaluate Client 2
DEBUG flwr 2023-10-26 11:25:54,432 | server.py:187 | evaluate_round 1 received 10 results and 0 failures
DEBUG flwr 2023-10-26 11:25:54,433 | main.py:216 | current metrics: [(96, {'accuracy': 0.6145833333333334}), (115, {'accuracy': 0.6521739130434783}), (96, {'accuracy': 0.6145833333333334}), (109, {'accuracy': 0.5688073394495413}), (104, {'accuracy': 0.5769230769230769}), (123, {'accuracy': 0.5203252032520326}), (89, {'accuracy': 0.6179775280898876}), (99, {'accuracy': 0.5959595959595959}), (118, {'accuracy': 0.652542372881356}), (110, {'accuracy': 0.5181818181818182})]
DEBUG flwr 2023-10-26 11:25:54,434 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 10)
DEBUG flwr 2023-10-26 11:25:54,820 | server.py:236 | fit_round 2 received 10 results and 0 failures
DEBUG flwr 2023-10-26 11:25:54,825 | server.py:173 | evaluate_round 2: strategy sampled 10 clients (out of 10)
DEBUG flwr 2023-10-26 11:25:55,078 | server.py:187 | evaluate_round 2 received 10 results and 0 failures
DEBUG flwr 2023-10-26 11:25:55,078 | main.py:216 | current metrics: [(99, {'accuracy': 0.8585858585858586}), (96, {'accuracy': 0.7291666666666666}), (104, {'accuracy': 0.8653846153846154}), (96, {'accuracy': 0.75}), (110, {'accuracy': 0.8181818181818182}), (118, {'accuracy': 0.788135593220339}), (109, {'accuracy': 0.5688073394495413}), (89, {'accuracy': 0.6741573033707865}), (115, {'accuracy': 0.782608695652174}), (123, {'accuracy': 0.7479674796747967})]
DEBUG flwr 2023-10-26 11:25:55,079 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 10)
DEBUG flwr 2023-10-26 11:25:55,545 | server.py:236 | fit_round 3 received 10 results and 0 failures
DEBUG flwr 2023-10-26 11:25:55,551 | server.py:173 | evaluate_round 3: strategy sampled 10 clients (out of 10)
DEBUG flwr 2023-10-26 11:25:55,899 | server.py:187 | evaluate_round 3 received 10 results and 0 failures
DEBUG flwr 2023-10-26 11:25:55,899 | main.py:216 | current metrics: [(96, {'accuracy': 0.8333333333333334}), (109, {'accuracy': 0.5688073394495413}), (89, {'accuracy': 0.7752808988764045}), (104, {'accuracy': 0.8461538461538461}), (115, {'accuracy': 0.8434782608695652}), (118, {'accuracy': 0.788135593220339}), (99, {'accuracy': 0.8787878787878788}), (123, {'accuracy': 0.8048780487804879}), (96, {'accuracy': 0.75}), (110, {'accuracy': 0.8272727272727273})]
DEBUG flwr 2023-10-26 11:25:55,901 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 10)
DEBUG flwr 2023-10-26 11:25:56,429 | server.py:236 | fit_round 4 received 10 results and 0 failures
DEBUG flwr 2023-10-26 11:25:56,434 | server.py:173 | evaluate_round 4: strategy sampled 10 clients (out of 10)
DEBUG flwr 2023-10-26 11:25:56,743 | server.py:187 | evaluate_round 4 received 10 results and 0 failures
DEBUG flwr 2023-10-26 11:25:56,744 | main.py:216 | current metrics: [(123, {'accuracy': 0.8048780487804879}), (110, {'accuracy': 0.8}), (115, {'accuracy': 0.8434782608695652}), (118, {'accuracy': 0.8050847457627118}), (109, {'accuracy': 0.5412844036697247}), (99, {'accuracy': 0.8585858585858586}), (104, {'accuracy': 0.8653846153846154}), (96, {'accuracy': 0.7604166666666666}), (96, {'accuracy': 0.8229166666666666}), (89, {'accuracy': 0.7640449438202247})]
DEBUG flwr 2023-10-26 11:25:56,745 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 10)
DEBUG flwr 2023-10-26 11:25:57,373 | server.py:236 | fit_round 5 received 10 results and 0 failures
DEBUG flwr 2023-10-26 11:25:57,380 | server.py:173 | evaluate_round 5: strategy sampled 10 clients (out of 10)
DEBUG flwr 2023-10-26 11:25:57,657 | server.py:187 | evaluate_round 5 received 10 results and 0 failures
DEBUG flwr 2023-10-26 11:25:57,658 | main.py:216 | current metrics: [(96, {'accuracy': 0.75}), (109, {'accuracy': 0.5321100917431193}), (99, {'accuracy': 0.8484848484848485}), (96, {'accuracy': 0.8229166666666666}), (110, {'accuracy': 0.7636363636363637}), (89, {'accuracy': 0.7528089887640449}), (118, {'accuracy': 0.7711864406779662}), (104, {'accuracy': 0.7980769230769231}), (115, {'accuracy': 0.8782608695652174}), (123, {'accuracy': 0.8211382113821138})]
DEBUG flwr 2023-10-26 11:25:57,659 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 10)
DEBUG flwr 2023-10-26 11:25:58,109 | server.py:236 | fit_round 6 received 10 results and 0 failures
DEBUG flwr 2023-10-26 11:25:58,114 | server.py:173 | evaluate_round 6: strategy sampled 10 clients (out of 10)
(DefaultActor pid=19452) DEBUG flwr 2023-10-26 11:25:58,336 | main.py:187 | Evaluate Client 7 [repeated 55x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)
DEBUG flwr 2023-10-26 11:25:59,586 | server.py:187 | evaluate_round 6 received 10 results and 0 failures
DEBUG flwr 2023-10-26 11:25:59,586 | main.py:216 | current metrics: [(109, {'accuracy': 0.5779816513761468}), (118, {'accuracy': 0.7711864406779662}), (115, {'accuracy': 0.8434782608695652}), (104, {'accuracy': 0.8461538461538461}), (123, {'accuracy': 0.8048780487804879}), (99, {'accuracy': 0.8484848484848485}), (110, {'accuracy': 0.8090909090909091}), (96, {'accuracy': 0.84375}), (89, {'accuracy': 0.7528089887640449}), (96, {'accuracy': 0.7916666666666666})]
DEBUG flwr 2023-10-26 11:25:59,589 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 10)
DEBUG flwr 2023-10-26 11:26:01,066 | server.py:236 | fit_round 7 received 10 results and 0 failures
DEBUG flwr 2023-10-26 11:26:01,076 | server.py:173 | evaluate_round 7: strategy sampled 10 clients (out of 10)
DEBUG flwr 2023-10-26 11:26:01,666 | server.py:187 | evaluate_round 7 received 10 results and 0 failures
DEBUG flwr 2023-10-26 11:26:01,666 | main.py:216 | current metrics: [(99, {'accuracy': 0.8585858585858586}), (104, {'accuracy': 0.8461538461538461}), (123, {'accuracy': 0.8211382113821138}), (109, {'accuracy': 0.5412844036697247}), (96, {'accuracy': 0.8125}), (89, {'accuracy': 0.7415730337078652}), (96, {'accuracy': 0.7708333333333334}), (115, {'accuracy': 0.8260869565217391}), (110, {'accuracy': 0.8090909090909091}), (118, {'accuracy': 0.7711864406779662})]
DEBUG flwr 2023-10-26 11:26:01,668 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 10)
DEBUG flwr 2023-10-26 11:26:02,282 | server.py:236 | fit_round 8 received 10 results and 0 failures
DEBUG flwr 2023-10-26 11:26:02,290 | server.py:173 | evaluate_round 8: strategy sampled 10 clients (out of 10)
DEBUG flwr 2023-10-26 11:26:02,794 | server.py:187 | evaluate_round 8 received 10 results and 0 failures
DEBUG flwr 2023-10-26 11:26:02,795 | main.py:216 | current metrics: [(123, {'accuracy': 0.7967479674796748}), (96, {'accuracy': 0.8020833333333334}), (96, {'accuracy': 0.7604166666666666}), (109, {'accuracy': 0.5321100917431193}), (104, {'accuracy': 0.8461538461538461}), (118, {'accuracy': 0.788135593220339}), (99, {'accuracy': 0.8686868686868687}), (115, {'accuracy': 0.808695652173913}), (89, {'accuracy': 0.7528089887640449}), (110, {'accuracy': 0.8090909090909091})]
INFO flwr 2023-10-26 11:26:02,796 | server.py:153 | FL finished in 10.853159699996468
INFO flwr 2023-10-26 11:26:02,822 | app.py:225 | app_fit: losses_distributed [(1, 0.0), (2, 0.0), (3, 0.0), (4, 0.0), (5, 0.0), (6, 0.0), (7, 0.0), (8, 0.0)]        
INFO flwr 2023-10-26 11:26:02,825 | app.py:226 | app_fit: metrics_distributed_fit {}
INFO flwr 2023-10-26 11:26:02,827 | app.py:227 | app_fit: metrics_distributed {'accuracy': [(1, 0.5920679886685553), (2, 0.7592067988668555), (3, 0.7913125590179415), (4, 0.7865911237016053), (5, 0.7743153918791312), (6, 0.7884796978281398), (7, 0.7799811142587346), (8, 0.7762039660056658)]}
INFO flwr 2023-10-26 11:26:02,828 | app.py:228 | app_fit: losses_centralized []
INFO flwr 2023-10-26 11:26:02,829 | app.py:229 | app_fit: metrics_centralized {}
HIST History (loss, distributed):
        round 1: 0.0
        round 2: 0.0
        round 3: 0.0
        round 4: 0.0
        round 5: 0.0
        round 6: 0.0
        round 7: 0.0
        round 8: 0.0
History (metrics, distributed, evaluate):
{'accuracy': [(1, 0.5920679886685553), (2, 0.7592067988668555), (3, 0.7913125590179415), (4, 0.7865911237016053), (5, 0.7743153918791312), (6, 0.7884796978281398), (7, 0.7799811142587346), (8, 0.7762039660056658)]}
(DefaultActor pid=8848) DEBUG flwr 2023-10-26 11:26:02,753 | main.py:187 | Evaluate Client 1 [repeated 24x across cluster]